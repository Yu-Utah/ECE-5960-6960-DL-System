{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "template_inclass_programming_02/16_2022.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnN9Zx0MowHj"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# how many samples per batch to load\n",
        "batch_size = 512\n",
        "\n",
        "# convert data to torch.FloatTensor\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "#transform=transforms.Compose([transforms.ToTensor(),\n",
        "#                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "#                             ])\n",
        "\n",
        "# choose the training and test datasets\n",
        "train_data = datasets.MNIST(root='data', train=True,\n",
        "                                   download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='data', train=False,\n",
        "                                  download=True, transform=transform)\n",
        "\n",
        "# prepare data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "5SB1Upjdo1Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "## Define the NN architecture\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear( 28*28 , 512 ) \n",
        "        # linear layer (n_hidden -> hidden_2)\n",
        "        self.fc2 = nn.Linear( 512, 10)\n",
        "        # linear layer (n_hidden -> ?)\n",
        "        # self.fc3 = nn.Linear(,)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # flatten image input\n",
        "        x = x.view(-1, 28*28) \n",
        "        # add hidden layer, with relu activation function\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# initialize the NN\n",
        "model_mlp = MLP().cuda()\n",
        "print(model_mlp)\n",
        "for parameter in model_mlp.parameters():\n",
        "    print(parameter.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7CnHQaZrJTd",
        "outputId": "d6a68618-86db-46cd-803a-2a7fc1c94ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "torch.Size([512, 784])\n",
            "torch.Size([512])\n",
            "torch.Size([10, 512])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(         \n",
        "            nn.Conv2d(in_channels= ,out_channels= , kernel_size= ,stride= ,padding= ),                              \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(kernel_size= ),    \n",
        "        )\n",
        "        self.conv2 = nn.Sequential(         \n",
        "            nn.Conv2d( ),     \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d( ),                \n",
        "        )\n",
        "        # fully connected layer, output 10 classes\n",
        "        self.out = nn.Linear( , 10)\n",
        "    def forward(self, x):\n",
        " \n",
        "        return output, x    # return x for visualization\n",
        "\n",
        "# initialize the NN\n",
        "model_cnn = CNN().cuda()\n",
        "print(model_cnn)\n",
        "pcount = 0\n",
        "for parameter in model_cnn.parameters():\n",
        "    print(parameter.shape)"
      ],
      "metadata": {
        "id": "BdcwayTgOksa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training code\n",
        "def train(model, optimizer, epochs=10):\n",
        "    model.train() # prep model for training\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        # monitor training loss\n",
        "        train_loss = 0.0\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        for data, target in train_loader:\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)[0]\n",
        "            #print(output, data.shape)\n",
        "            # calculate the loss\n",
        "            loss = criterion(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "            # update running training loss\n",
        "            train_loss += loss.item()*data.size(0)\n",
        "            \n",
        "        # print training statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = train_loss/len(train_loader.dataset)\n",
        "\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
        "            epoch+1, \n",
        "            train_loss\n",
        "            ))"
      ],
      "metadata": {
        "id": "UWMmDwt_s52n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize lists to monitor test loss and accuracy\n",
        "def test(model):\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "\n",
        "    model.eval() # prep model for *evaluation*\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        data = data.cuda()\n",
        "        target = target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)[0]\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update test loss \n",
        "        test_loss += loss.item()*data.size(0)\n",
        "        # convert output probabilities to predicted class\n",
        "        _, pred = torch.max(output, 1)\n",
        "        # compare predictions to true label\n",
        "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "        # calculate test accuracy for each object class\n",
        "        for i in range(data.shape[0]):\n",
        "            label = target.data[i]\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "    # calculate and print avg test loss\n",
        "    test_loss = test_loss/len(test_loader.dataset)\n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    for i in range(10):\n",
        "        if class_total[i] > 0:\n",
        "            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "                str(i), 100 * class_correct[i] / class_total[i],\n",
        "                np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "        else:\n",
        "            print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "    print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "        100. * np.sum(class_correct) / np.sum(class_total),\n",
        "        np.sum(class_correct), np.sum(class_total)))"
      ],
      "metadata": {
        "id": "9mcGy6v5v0pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 10  # suggest training between 20-50 epochs\n",
        "# specify optimizer\n",
        "#model = Net()\n",
        "optimizer = torch.optim.SGD(model_cnn.parameters(), lr=0.05)\n",
        "train(model_cnn, optimizer)"
      ],
      "metadata": {
        "id": "eX8uYRNLuBeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(model_cnn)"
      ],
      "metadata": {
        "id": "HTLyh1_fwcd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVFXFjXfbSE8",
        "outputId": "e746814f-7fcb-4e82-91ff-9aacc742032a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_BN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_BN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(         \n",
        "            nn.Conv2d( ),                              \n",
        "            nn.ReLU6(),                      \n",
        "            nn.MaxPool2d(kernel_size=2),    \n",
        "        )\n",
        "        self.conv2 = nn.Sequential(         \n",
        "            nn.Conv2d( ),     \n",
        "            nn.ReLU6(),                      \n",
        "            nn.MaxPool2d(2),                \n",
        "        )\n",
        "        # fully connected layer, output 10 classes\n",
        "        self.bn1 = nn.BatchNorm1d( , affine=False)\n",
        "        self.out = nn.Linear( , 10)\n",
        "    def forward(self, x):\n",
        "        ...\n",
        "        return output, x    # return x for visualization\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "ZL1zlB3oaWi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 10  # suggest training between 20-50 epochs\n",
        "# specify optimizer\n",
        "#model = Net()\n",
        "# re-initialize the NN\n",
        "model_cnn3 = CNN_BN().cuda()\n",
        "print(model_cnn3)\n",
        "\n",
        "optimizer = torch.optim.Adam(model_cnn3.parameters(), lr=0.02)\n",
        "train(model_cnn3, optimizer)"
      ],
      "metadata": {
        "id": "ErsQSGGEcpyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(model_cnn3)"
      ],
      "metadata": {
        "id": "VQufQml4dYNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 10  # suggest training between 20-50 epochs\n",
        "# specify optimizer\n",
        "#model = Net()\n",
        "# re-initialize the NN\n",
        "model_cnn3 = CNN_BN().cuda()\n",
        "print(model_cnn3)\n",
        "\n",
        "optimizer = torch.optim.Adam(model_cnn3.parameters(), lr=0.015)\n",
        "train(model_cnn3, optimizer)\n",
        "test(model_cnn3)"
      ],
      "metadata": {
        "id": "KbLZdSimh98W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}