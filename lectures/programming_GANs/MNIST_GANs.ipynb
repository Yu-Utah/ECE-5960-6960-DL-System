{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST-GANs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Mflc-T7Gnngx"
      },
      "outputs": [],
      "source": [
        "% matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from torchvision import datasets, models, transforms, utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 512\n",
        "G_lr = D_lr = 1e-3\n",
        "global_step = 0\n",
        "print_every = 1000\n",
        "total_steps = 10000\n",
        "cost_func = nn.BCELoss()\n",
        "\n",
        "D_ent = 100\n",
        "D_side = 28\n",
        "D_img = D_side**2\n",
        "D_hidden = 128"
      ],
      "metadata": {
        "id": "llzk5LmHnr8A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modes = ['train', 'val']\n",
        "trans = transforms.Compose([transforms.ToTensor(),]) # transforms.Normalize((0.1307,), (0.3081,))\n",
        "dsets = {k: datasets.MNIST('./data', train=k=='train', download=True, transform=trans) for k in modes}\n",
        "loaders = {k: torch.utils.data.DataLoader(dsets[k], batch_size=batch_size, shuffle=True) for k in modes}\n",
        "\n",
        "def entropy():\n",
        "    return Variable(torch.randn(batch_size, D_ent))\n",
        "\n",
        "def mnist():\n",
        "    data = next(iter(loaders['train']))[0]\n",
        "    return Variable(data).resize(batch_size, D_img)"
      ],
      "metadata": {
        "id": "ZSRKUbMtntXk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(inp, c, save=False, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    fig = plt.figure(figsize=(5, 5))\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    plt.imshow(inp)\n",
        "    \n",
        "    plt.title(title) if title is not None else plt.title(str(c).zfill(3))\n",
        "    if save:\n",
        "        if not os.path.exists('cnn-out/'):\n",
        "            os.makedirs('cnn-out/')\n",
        "        plt.savefig('cnn-out/{}.png'.format(str(c).zfill(3)), bbox_inches='tight')\n",
        "        plt.close(fig)\n",
        "\n",
        "#inputs = mnist().data.resize(batch_size,1,D_side,D_side)\n",
        "#out = utils.make_grid(inputs)\n",
        "#imshow(out, c=0, save=False, title=\"Real MNIST digits\")"
      ],
      "metadata": {
        "id": "jy3DwrAsnu8V"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a generic CNN for MNIST, see github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.resize(batch_size,1,D_side,D_side)\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.sigmoid(x)\n",
        "    \n",
        "# a vanilla neural network with one hidden layer\n",
        "class SimpleNN(torch.nn.Module):\n",
        "    def __init__(self, batch_size, input_dim, h_dim, output_dim):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.W1 = nn.Parameter(torch.randn(input_dim, h_dim)*0.075)\n",
        "        self.b1 = nn.Parameter(torch.randn(h_dim)*0.075)\n",
        "        self.W2 = nn.Parameter(torch.randn(h_dim, output_dim)*0.075)\n",
        "        self.b2 = nn.Parameter(torch.randn(output_dim)*0.075)\n",
        "\n",
        "    def forward(self, X):\n",
        "        h = F.relu(X.mm(self.W1) + self.b1.repeat(X.size(0), 1))\n",
        "        return F.sigmoid(h.mm(self.W2) + self.b2.repeat(X.size(0), 1))\n",
        "    \n",
        "D = SimpleCNN()\n",
        "G = SimpleNN(batch_size, D_ent, D_hidden, D_img)"
      ],
      "metadata": {
        "id": "ynugSOqKoDNN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = {'D': torch.optim.Adam(D.parameters(), lr=D_lr),\n",
        "              'G': torch.optim.Adam(G.parameters(), lr=G_lr)}\n",
        "ones_label = Variable(torch.ones(batch_size))\n",
        "zeros_label = Variable(torch.zeros(batch_size))\n",
        "\n",
        "# generic train loop\n",
        "for global_step in range(global_step, total_steps+global_step):\n",
        "    \n",
        "    # ======== DISCRIMINATOR STEP ======== #\n",
        "    # forward\n",
        "    z = entropy() ; X = mnist()\n",
        "    G_sample = G(z)\n",
        "    D_real = D(X)\n",
        "    D_fake = D(G_sample)\n",
        "    #print(D_real.view( 64,1 ).shape, ones_label.shape)\n",
        "    # backward\n",
        "    D_loss_real = cost_func(D_real, ones_label.view( batch_size, 1))\n",
        "    D_loss_fake = cost_func(D_fake, zeros_label.view( batch_size, 1))\n",
        "    D_loss = D_loss_real + D_loss_fake\n",
        "    D_loss.backward()\n",
        "    optimizers['D'].step()\n",
        "    [o.zero_grad() for o in optimizers.values()]\n",
        "    \n",
        "    # ======== GENERATOR STEP ======== #\n",
        "    # forward\n",
        "    z = entropy()\n",
        "    G_sample = G(z)\n",
        "    D_fake = D(G_sample)\n",
        "    \n",
        "    # backward\n",
        "    G_loss = cost_func(D_fake, ones_label.view( batch_size, 1))\n",
        "    G_loss.backward()\n",
        "    optimizers['G'].step()\n",
        "    [o.zero_grad() for o in optimizers.values()]\n",
        "\n",
        "    # ======== DISPLAY PROGRESS ======== #\n",
        "    if global_step % print_every == 0:\n",
        "        print('step {}: D loss: {:.4f}; G loss: {:.4f}'\n",
        "              .format(global_step, D_loss.data.numpy(), G_loss.data.numpy()))\n",
        "        \n",
        "        samples = G(entropy()).data.resize(batch_size,1,D_side,D_side)\n",
        "        samples = utils.make_grid(samples)\n",
        "        imshow(samples, c = global_step // print_every, save=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob_aJ_7foFwy",
        "outputId": "195ffcb5-cea3-4984-ddbc-60661c55e7c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:493: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: D loss: 1.3915; G loss: 0.6989\n",
            "step 1000: D loss: 0.0805; G loss: 5.8383\n",
            "step 2000: D loss: 0.2407; G loss: 3.6489\n",
            "step 3000: D loss: 0.2964; G loss: 2.9695\n",
            "step 4000: D loss: 0.3345; G loss: 2.8568\n"
          ]
        }
      ]
    }
  ]
}